# OpenAIç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
# import os
# from langchain_openai import ChatOpenAI

# Ollamaç”¨
from langchain_ollama import ChatOllama
import requests
import json

def _fetch_ollama_tags(base_url: str = "http://localhost:11434") -> dict:
    """
    Ollamaã® /api/tags ã‚’å–å¾—ã™ã‚‹ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ï¼‰ã€‚

    Raises:
        ConnectionError: æ¥ç¶šä¸å¯/HTTPã‚¨ãƒ©ãƒ¼
        ValueError: JSONã¨ã—ã¦è§£é‡ˆã§ããªã„
    """
    try:
        response = requests.get(f"{base_url}/api/tags", timeout=5)
        response.raise_for_status()
    except requests.exceptions.RequestException as e:
        raise ConnectionError(
            "Ollamaã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚OllamaãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n"
            "ğŸ’¡ å¯¾å‡¦æ–¹æ³•: `ollama serve` ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã€Ollamaã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚\n"
            f"è©³ç´°: {e}"
        )

    try:
        return response.json()
    except json.JSONDecodeError as e:
        raise ValueError(f"Ollama APIã®å¿œç­”ãŒJSONã§ã¯ã‚ã‚Šã¾ã›ã‚“: {e}")

def check_ollama_connection(base_url: str = "http://localhost:11434") -> bool:
    """
    Ollamaã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šã‚’ç¢ºèªã™ã‚‹
    
    Args:
        base_url: Ollamaã®ãƒ™ãƒ¼ã‚¹URL
    
    Returns:
        æ¥ç¶šå¯èƒ½ãªå ´åˆTrue
    """
    try:
        _fetch_ollama_tags(base_url)
        return True
    except Exception:
        return False

def get_llm(
    model_name: str = "gemma3:4b",
    base_url: str = "http://localhost:11434",
    temperature: float = 0.7,
    num_predict: int | None = None,
    repeat_penalty: float | None = None,
    repeat_last_n: int | None = None,
    stop: list[str] | None = None,
    verify_model: bool = True,
):
    """
    Ollamaã‚’ä½¿ç”¨ã—ã¦LLMã‚’å–å¾—ã™ã‚‹
    
    Args:
        model_name: ä½¿ç”¨ã™ã‚‹Ollamaãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: gemma3:4bï¼‰
        base_url: Ollamaã®ãƒ™ãƒ¼ã‚¹URLï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: http://localhost:11434ï¼‰
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.7ï¼‰
        num_predict: ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆOllamaå´ã®ä¸Šé™ï¼‰
        repeat_penalty: åå¾©æŠ‘åˆ¶ï¼ˆ1.0ã‚ˆã‚Šå¤§ãã„ã»ã©åå¾©ã—ã«ãã„ï¼‰
        repeat_last_n: ç›´è¿‘Nãƒˆãƒ¼ã‚¯ãƒ³ã‚’åå¾©åˆ¤å®šã«ä½¿ã†
        stop: ç”Ÿæˆåœæ­¢ã‚·ãƒ¼ã‚±ãƒ³ã‚¹
    
    Returns:
        ChatOllamaã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    
    Raises:
        ConnectionError: Ollamaã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šã§ããªã„å ´åˆ
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    if verify_model:
        # /api/tags ã‚’1å›ã ã‘å–å¾—ã—ã¦ã€æ¥ç¶šç¢ºèªã¨ãƒ¢ãƒ‡ãƒ«å­˜åœ¨ç¢ºèªã‚’ã¾ã¨ã‚ã¦è¡Œã†
        tags = _fetch_ollama_tags(base_url)
        models = [m.get("name") for m in tags.get("models", []) if isinstance(m, dict) and m.get("name")]
        if model_name not in models:
            raise ValueError(
                f"ãƒ¢ãƒ‡ãƒ« '{model_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚\n"
                f"åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {', '.join(models) if models else 'ãªã—'}\n"
                f"ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯: `ollama pull {model_name}`"
            )
    
    return ChatOllama(
        model=model_name,
        temperature=temperature,
        base_url=base_url,
        num_predict=num_predict,
        repeat_penalty=repeat_penalty,
        repeat_last_n=repeat_last_n,
        stop=stop,
    )
    
    # OpenAIç”¨ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # api_key = os.getenv("OPENAI_API_KEY")
    # if not api_key:
    #     raise ValueError("OPENAI_API_KEY not found in environment variables")
    # return ChatOpenAI(model=model_name, api_key=api_key, temperature=0.7)

