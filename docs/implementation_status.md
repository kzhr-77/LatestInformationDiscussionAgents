# 現在の実装状況

**最終更新日**: 2025-12-19
**プロジェクト**: LatestInformationDiscussionAgents

本書は、現在の実装状況をまとめたものです。

## 1. フォルダ構成

プロジェクトの構造は以下のように初期化されています：

```
LatestInformationDiscussionAgents/
├── docs/                   # ドキュメント (本フォルダ)
├── src/
│   ├── agents/             # エージェントロジックの実装
│   ├── core/               # オーケストレーションロジック (LangGraph)
│   ├── models/             # データスキーマ (Pydantic)
│   ├── ui/                 # ユーザーインターフェース (Streamlit)
│   └── utils/              # ユーティリティ (LLM, ツール)
├── main.py                 # CLIエントリーポイント
├── requirements.txt        # 依存ライブラリ
└── .env                    # 設定 (APIキー)
```

## 2. コンポーネントの状態

### エージェント (`src/agents/`)
| エージェントファイル | 役割 | 現在の状態 | 未実装のロジック |
| :--- | :--- | :--- | :--- |
| `researcher.py` | ニュース記事取得 (フェーズ 0) | ✅ **実装完了** | - |
| | | - URL判定機能 | |
| | | - URLからの記事取得（BeautifulSoup） | |
| | | - RSS/公式フィード許可リスト方式のキーワード検索（外部検索APIなし運用） | |
| | | - 本文抽出のノイズ削減（タグ除去、段階抽出、重複行除去） | |
| | | - 日本語クエリでもヒットしやすいマッチ（簡易N-gram補助） | |
| | | - エラーハンドリング | |
| `analyst_optimistic.py` | 楽観的分析 (フェーズ 1, 3) | ✅ **フェーズ1/3 実装完了** | - |
| | | - LLMプロンプト実装 | |
| | | - 構造化出力（Argument型） | |
| | | - エラーハンドリング | |
| `analyst_pessimistic.py` | 悲観的分析 (フェーズ 1, 3) | ✅ **フェーズ1/3 実装完了** | - |
| | | - LLMプロンプト実装 | |
| | | - 構造化出力（Argument型） | |
| | | - エラーハンドリング | |
| `fact_checker.py` | ファクトチェック (フェーズ 2) | ✅ **実装完了** | - |
| | | - LLMプロンプト実装（客観的検証プロンプト） | |
| | | - 構造化出力（Critique型） | |
| | | - 温度パラメータ0.3での実行 | |
| | | - 出力の正規化（`factual_errors` 200文字制限、重複除去） | |
| | | - エラーハンドリング | |
| `reporter.py` | 最終レポート (フェーズ 4) | ✅ **実装完了（実LLMで確認済み）** | レポート品質のさらなる改善（一般論の抑制、根拠の明示強化） |

### コアロジック (`src/core/`)
- **`state.py`**:
    - `DiscussionState` (TypedDict) が定義され、主張、批評、最終レポートのフィールドを持つ。
    - ✅ `optimistic_rebuttal` と `pessimistic_rebuttal` フィールドを追加済み。
    - ✅ `request_id` を追加（ログでUI→グラフ→各ノードの相関追跡に利用）。
    - ✅ `halt` / `halt_reason` を追加（RSS一致なし等で早期終了するため）。
- **`graph.py`**:
    - `StateGraph` が定義され、Researcher -> Analysts -> Checker -> Reporter -> End と接続されている。
    - ✅ フェーズ3（反論）ステップを追加し、`optimistic_rebuttal` / `pessimistic_rebuttal` を生成する。
    - ✅ RSS一致なしの場合は `halt=True` で **早期終了**（後続フェーズを実行しない）。
    - ✅ ログを `logging` に統一し、例外時もグラフが完走（フォールバックで継続）するようにしている。
    - ✅ LLM設定を用途別プロファイルに集約（fact_checkは低温＋反復抑制）。
    - ✅ reporterへフェーズ0-3の出力を渡し、FinalReportを生成する（フェーズ4本実装）。

### モデル (`src/models/`)
- **`schemas.py`**: 基本的なPydanticモデル (`Argument`, `Critique`, `FinalReport`, `Rebuttal`) が定義されている。
  - ✅ リスト系フィールドを `default_factory=list` で安全化（構造化出力のキー欠落でも落ちにくくする）。

### ユーザーインターフェース (`src/ui/`)
- **`streamlit_app.py`**:
    - 基本的なUIが実装されている。
    - 入力: トピック/URL、APIキー。
    - 出力: グラフからのモック辞書出力を表示。
    - **状態**: モック化されたグラフに接続済み。
    - ✅ `request_id` を生成してstateに渡す（ログ追跡用）。
    - ✅ ログ初期化（UTF-8ファイルログ＋コンソール）を追加。
    - ✅ フェーズ3（反論）を表示。
    - ✅ RSS一致なし等の `halt` を検知したら、理由を表示して処理を終了。
    - ✅ FinalReportの `article_info`（3行）/結論/批評ポイントを表示。

### テスト/スモーク (`tools/`, `src/utils/`)
- ✅ 外部依存なしのスモークを追加
  - `tools/smoke_phase3_no_ollama.py`: フェーズ3を含む完走と出力キー検証（LLMは強制失敗モデルでフォールバック経路を通す）
  - `tools/smoke_rss_no_keyword_exits.py`: RSS一致なし時に通知して早期終了することを検証
  - `src/utils/testing_models.py`: `AlwaysFailChatModel`（スモーク用）

## 3. 実装待ちタスク

`仕様.md` に基づいてシステムを完成させるためには、以下のロジックを実装する必要があります：

1.  ✅ **検索統合**: `ResearcherAgent` に `TavilySearchResults` を実装する。**完了**
2.  ✅ **LLMプロンプト（楽観的・悲観的アナリスト）**: フェーズ1用のプロンプトを実装。**完了**
3.  ✅ **構造化出力（楽観的・悲観的アナリスト）**: `.with_structured_output()` を使用して `Argument` 型を返すように実装。**完了**
4.  ✅ **ファクトチェッカー実装**: フェーズ2用のLLMプロンプトと構造化出力（Critique型）を実装。**完了**
5.  **討論ロジック**:
    - ✅ `DiscussionState` を更新し、反論データを保持できるようにする。**完了**
    - ✅ `graph.py` を更新し、アナリストが批評に応答する「討論」ステップ (フェーズ 3) を含める。**完了**
6.  ✅ **RSS一致なし時の早期終了**: RSSフィードにキーワード一致が無い場合は理由を通知し、後続フェーズを実行せず終了する。**完了**
7.  ✅ **フェーズ4（レポート）本実装**: 全フェーズの出力を統合し `FinalReport` を生成する。**完了**
8.  **グラフの洗練**: ステップ間でデータが正しく渡されるようにする（例：記事をアナリストへ、主張をチェッカーへ、反論/批評をレポータへ）。**完了**

## 4. 今後の変更方針（安全重視・外部検索APIなし）

### 方針: RSS/公式フィードを用いたキーワード検索（許可リスト方式）
- **背景**: `TAVILY_API_KEY` のような外部検索APIキーに依存せず、かつ規約/安定性の観点で安全寄りの運用に寄せる。
- **変更点（実装済み）**:
  - `ResearcherAgent` の「キーワード検索」を **RSS集約検索（許可リスト方式）優先**に切替済み。
  - 許可リストは **環境変数 `RSS_FEED_URLS`** または **`config/rss_feeds.txt`** から読み込む。
  - フィード内のタイトル/概要に対してキーワードマッチし、候補URLを選定 → 既存のURL本文取得ロジックで本文取得。
  - ✅ 既定は **最上位1記事**（複数記事混在で分析がブレるのを防ぐ）。必要に応じて `RSS_MAX_ARTICLES`（1〜3）で増やせる。
  - Tavilyは **APIキーがある場合のみ任意のフォールバック**として残している（外部検索APIなし運用が可能）。
- **設計上の安全策**:
  - クロール範囲を「許可したRSSソース」に限定し、無差別なWebクロールは行わない。
  - 取得失敗時は無理に探索せず「候補なし」として扱う。

## 5. 直近の進捗（最新）

- ✅ **P0/P1の改善**（安定性/運用性/精度の底上げ）
  - ログ基盤: `print` → `logging`、UTF-8ファイルログ、`request_id` による相関追跡。
  - 本文抽出: ノイズ削減（不要タグ除去、段階抽出、重複行除去）。
  - RSS検索: 日本語クエリのヒット率改善（簡易N-gram補助）、既定1記事に変更。
  - LLM設定: 用途別プロファイルへ集約（fact_checkは低温＋反復抑制）。
- ✅ **Phase2表示の重複対策**
  - ファクトチェッカーの出力を正規化し、同一内容の重複行（例: 「楽観的アナリスト: …」が複数回）を除去。
- ✅ **Phase3（討論/反論）**
  - 反論生成を実装し、グラフにフェーズ3を追加。UIに反論表示を追加。
- ✅ **RSS一致なし時の通知＋終了**
  - RSSフィードにキーワード一致が無い場合は `halt_reason` を返し、後続処理を終了。
- ✅ **外部依存なしスモーク**
  - Ollama無しで完走/早期終了を検証するスモークを追加。
- ✅ **Phase4（最終レポート）**
  - `ReporterAgent` を本実装化し、実LLM（Ollama）で `FinalReport` の生成を確認。
  - `optimistic_view`/`pessimistic_view` はstateの値をそのまま採用し、幻覚混入を抑制。
  - `article_info` は「タイトル/ソース/要約」の3行で安定化。
  - `critique_points` は入力（Critique/反論/本文一致チェック）からタグ付きで決定的に生成。
- ✅ **URL入力時のタイトル抽出**
  - URLからの記事取得時に `og:title` / `h1` / `title` 等からタイトルを抽出し、本文先頭に `[title]` を付与（RSSは二重ヘッダを回避）。
- ✅ **Phase4の品質調整（具体性の底上げ）**
  - Reporterが本文から「引用候補」を抜粋してプロンプトに渡し、要約が一般論に寄りすぎないように制約を追加。
  - `summary` / `final_conclusion` が期待フォーマットを満たさない場合に、後処理で最低限の具体性・根拠・注意点を付与。
- ✅ **FactCheckerの安定化（JSON復元の標準化）**
  - `Critique` は structured output に依存せず、JSON文字列出力→パース復元で安定化。
  - JSON抽出を「フェンス除去＋最初にパースできたJSON採用＋型補完」に強化し、出力揺れに耐性を持たせた。
- ✅ **Reporterの安定化（2段＋段階フォールバック）**
  - 事実抽出（facts）→統合（report）の2段に分割。
  - どちらかが失敗しても最終レポートが空にならないよう、機械抽出/テンプレ合成で段階フォールバックを追加。
- ✅ **URL本文抽出の精度向上（readability）**
  - `readability-lxml` を導入し、可能ならreadabilityで本文抽出→失敗時は従来抽出へフォールバック。
- ✅ **`get_llm()` のモデル事前確認をオプション化**
  - `/api/tags` を毎回叩かないため、`get_llm(..., verify_model=...)` を追加。グラフ側は `verify_model=False` で軽量化。

## 6. 次の作業（優先度順）

1. **レポート品質の調整（Phase4の磨き込み）**
   - 要約/統合結論の精度向上（記事本文に根拠の無い断定を抑制、論点の具体性を上げる）。
   - 特に「記事の内容」と「記事に紐づかない周辺ニュース/一般論」が混ざるケースを抑制する。
2. **FactCheckerのさらなる堅牢化（残課題）**
   - JSON抽出で対応できない「括弧がネストした長文」等のケースに備え、より厳密なJSON抽出（ストリームパーサ/括弧カウント）を検討。
   - 失敗時のログ観測性（rawの短い断片を安全に出す等）を整備する。
3. **Reporterのさらなる堅牢化（残課題）**
   - facts段/統合段の structured_output を必要に応じてJSON出力に統一し、モデル差をさらに吸収する。
   - extracted facts の品質評価（重複・一般論率・具体性）を簡易スコア化して、弱いときは抽出戦略を変える。
4. **本文抽出（readability）の改善（残課題）**
   - readability抽出が短すぎる/空になるサイトの改善（閾値判定・サイト別フォールバック・タイトル後処理）。
5. **UIのエラーメッセージ改善（残課題）**
   - `verify_model=False` により「モデル未取得」が実行時に顕在化するため、UI側で補助チェック（任意）を追加するか、例外整形を強化する。
6. **テスト拡充（任意）**
   - FactChecker JSONパースの単体テスト（フェンス/前置き/複数JSON/型崩れ）。
   - Reporterの段階フォールバックの単体テスト（facts失敗、report失敗、両方失敗）。


