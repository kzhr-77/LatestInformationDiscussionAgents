# 現在の実装状況

**最終更新日**: 2025-12-21
**プロジェクト**: LatestInformationDiscussionAgents

本書は、現在の実装状況をまとめたものです。

## 1. フォルダ構成

プロジェクトの構造は以下のように初期化されています：

```
LatestInformationDiscussionAgents/
├── docs/                   # ドキュメント (本フォルダ)
├── src/
│   ├── agents/             # エージェントロジックの実装
│   ├── core/               # オーケストレーションロジック (LangGraph)
│   ├── models/             # データスキーマ (Pydantic)
│   ├── ui/                 # ユーザーインターフェース (Streamlit)
│   └── utils/              # ユーティリティ (LLM, ツール)
├── main.py                 # CLIエントリーポイント
├── requirements.txt        # 依存ライブラリ
└── .env                    # 設定 (APIキー)
```

## 2. コンポーネントの状態

### エージェント (`src/agents/`)
| エージェントファイル | 役割 | 現在の状態 | 未実装のロジック |
| :--- | :--- | :--- | :--- |
| `researcher.py` | ニュース記事取得 (フェーズ 0) | ✅ **実装完了** | - |
| | | - URL判定機能 | |
| | | - URLからの記事取得（BeautifulSoup） | |
| | | - RSS/公式フィード許可リスト方式のキーワード検索（外部検索APIなし運用） | |
| | | - 本文抽出のノイズ削減（タグ除去、段階抽出、重複行除去） | |
| | | - 日本語クエリでもヒットしやすいマッチ（簡易N-gram補助） | |
| | | - エラーハンドリング | |
| `analyst_optimistic.py` | 楽観的分析 (フェーズ 1, 3) | ✅ **フェーズ1/3 実装完了** | - |
| | | - LLMプロンプト実装 | |
| | | - 構造化出力（Argument型） | |
| | | - エラーハンドリング | |
| `analyst_pessimistic.py` | 悲観的分析 (フェーズ 1, 3) | ✅ **フェーズ1/3 実装完了** | - |
| | | - LLMプロンプト実装 | |
| | | - 構造化出力（Argument型） | |
| | | - エラーハンドリング | |
| `fact_checker.py` | ファクトチェック (フェーズ 2) | ✅ **実装完了** | - |
| | | - LLMプロンプト実装（客観的検証プロンプト） | |
| | | - 構造化出力（Critique型） | |
| | | - 温度パラメータ0.3での実行 | |
| | | - 出力の正規化（`factual_errors` 200文字制限、重複除去） | |
| | | - エラーハンドリング | |
| `reporter.py` | 最終レポート (フェーズ 4) | ✅ **実装完了（実LLMで確認済み）** | レポート品質のさらなる改善（一般論の抑制、根拠の明示強化） |

### コアロジック (`src/core/`)
- **`state.py`**:
    - `DiscussionState` (TypedDict) が定義され、主張、批評、最終レポートのフィールドを持つ。
    - ✅ `optimistic_rebuttal` と `pessimistic_rebuttal` フィールドを追加済み。
    - ✅ `request_id` を追加（ログでUI→グラフ→各ノードの相関追跡に利用）。
    - ✅ `halt` / `halt_reason` を追加（RSS一致なし等で早期終了するため）。
- **`graph.py`**:
    - `StateGraph` が定義され、Researcher -> Analysts -> Checker -> Reporter -> End と接続されている。
    - ✅ フェーズ3（反論）ステップを追加し、`optimistic_rebuttal` / `pessimistic_rebuttal` を生成する。
    - ✅ RSS一致なしの場合は `halt=True` で **早期終了**（後続フェーズを実行しない）。
    - ✅ ログを `logging` に統一し、例外時もグラフが完走（フォールバックで継続）するようにしている。
    - ✅ LLM設定を用途別プロファイルに集約（fact_checkは低温＋反復抑制）。
    - ✅ reporterへフェーズ0-3の出力を渡し、FinalReportを生成する（フェーズ4本実装）。

### モデル (`src/models/`)
- **`schemas.py`**: 基本的なPydanticモデル (`Argument`, `Critique`, `FinalReport`, `Rebuttal`) が定義されている。
  - ✅ リスト系フィールドを `default_factory=list` で安全化（構造化出力のキー欠落でも落ちにくくする）。

### ユーザーインターフェース (`src/ui/`)
- **`streamlit_app.py`**:
    - 基本的なUIが実装されている。
    - 入力: トピック/URL、APIキー。
    - 出力: グラフからのモック辞書出力を表示。
    - **状態**: モック化されたグラフに接続済み。
    - ✅ `request_id` を生成してstateに渡す（ログ追跡用）。
    - ✅ ログ初期化（UTF-8ファイルログ＋コンソール）を追加。
    - ✅ フェーズ3（反論）を表示。
    - ✅ RSS一致なし等の `halt` を検知したら、理由を表示して処理を終了。
    - ✅ FinalReportの `article_info`（3行）/結論/批評ポイントを表示。

### テスト/スモーク (`tools/`, `src/utils/`)
- ✅ 外部依存なしのスモークを追加
  - `tools/smoke_phase3_no_ollama.py`: フェーズ3を含む完走と出力キー検証（LLMは強制失敗モデルでフォールバック経路を通す）
  - `tools/smoke_rss_no_keyword_exits.py`: RSS一致なし時に通知して早期終了することを検証
  - `src/utils/testing_models.py`: `AlwaysFailChatModel`（スモーク用）
 - ✅ 単体テスト（unittest）を追加
   - `tests/test_fact_checker_json_parsing.py`
   - `tests/test_reporter_fallback.py`
   - `tests/test_security_utils.py`（SSRF/URL検証）

## 3. 実装待ちタスク

`仕様.md` に基づいてシステムを完成させるためには、以下のロジックを実装する必要があります：

1.  ✅ **検索統合**: `ResearcherAgent` に `TavilySearchResults` を実装する。**完了**
2.  ✅ **LLMプロンプト（楽観的・悲観的アナリスト）**: フェーズ1用のプロンプトを実装。**完了**
3.  ✅ **構造化出力（楽観的・悲観的アナリスト）**: `.with_structured_output()` を使用して `Argument` 型を返すように実装。**完了**
4.  ✅ **ファクトチェッカー実装**: フェーズ2用のLLMプロンプトと構造化出力（Critique型）を実装。**完了**
5.  **討論ロジック**:
    - ✅ `DiscussionState` を更新し、反論データを保持できるようにする。**完了**
    - ✅ `graph.py` を更新し、アナリストが批評に応答する「討論」ステップ (フェーズ 3) を含める。**完了**
6.  ✅ **RSS一致なし時の早期終了**: RSSフィードにキーワード一致が無い場合は理由を通知し、後続フェーズを実行せず終了する。**完了**
7.  ✅ **フェーズ4（レポート）本実装**: 全フェーズの出力を統合し `FinalReport` を生成する。**完了**
8.  **グラフの洗練**: ステップ間でデータが正しく渡されるようにする（例：記事をアナリストへ、主張をチェッカーへ、反論/批評をレポータへ）。**完了**

## 4. 今後の変更方針（安全重視・外部検索APIなし）

### 方針: RSS/公式フィードを用いたキーワード検索（許可リスト方式）
- **背景**: `TAVILY_API_KEY` のような外部検索APIキーに依存せず、かつ規約/安定性の観点で安全寄りの運用に寄せる。
- **変更点（実装済み）**:
  - `ResearcherAgent` の「キーワード検索」を **RSS集約検索（許可リスト方式）優先**に切替済み。
  - 許可リストは **環境変数 `RSS_FEED_URLS`** または **`config/rss_feeds.txt`** から読み込む。
  - フィード内のタイトル/概要に対してキーワードマッチし、候補URLを選定 → 既存のURL本文取得ロジックで本文取得。
  - ✅ 既定は **最上位1記事**（複数記事混在で分析がブレるのを防ぐ）。必要に応じて `RSS_MAX_ARTICLES`（1〜3）で増やせる。
  - Tavilyは **APIキーがある場合のみ任意のフォールバック**として残している（外部検索APIなし運用が可能）。
- **設計上の安全策**:
  - クロール範囲を「許可したRSSソース」に限定し、無差別なWebクロールは行わない。
  - 取得失敗時は無理に探索せず「候補なし」として扱う。

## 5. 直近の進捗（最新）

- ✅ **P0/P1の改善**（安定性/運用性/精度の底上げ）
  - ログ基盤: `print` → `logging`、UTF-8ファイルログ、`request_id` による相関追跡。
  - 本文抽出: ノイズ削減（不要タグ除去、段階抽出、重複行除去）。
  - RSS検索: 日本語クエリのヒット率改善（簡易N-gram補助）、既定1記事に変更。
  - LLM設定: 用途別プロファイルへ集約（fact_checkは低温＋反復抑制）。
- ✅ **Phase2表示の重複対策**
  - ファクトチェッカーの出力を正規化し、同一内容の重複行（例: 「楽観的アナリスト: …」が複数回）を除去。
- ✅ **Phase3（討論/反論）**
  - 反論生成を実装し、グラフにフェーズ3を追加。UIに反論表示を追加。
- ✅ **RSS一致なし時の通知＋終了**
  - RSSフィードにキーワード一致が無い場合は `halt_reason` を返し、後続処理を終了。
- ✅ **外部依存なしスモーク**
  - Ollama無しで完走/早期終了を検証するスモークを追加。
- ✅ **Phase4（最終レポート）**
  - `ReporterAgent` を本実装化し、実LLM（Ollama）で `FinalReport` の生成を確認。
  - `optimistic_view`/`pessimistic_view` はstateの値をそのまま採用し、幻覚混入を抑制。
  - `article_info` は「タイトル/ソース/要約」の3行で安定化。
  - `critique_points` は入力（Critique/反論/本文一致チェック）からタグ付きで決定的に生成。
- ✅ **URL入力時のタイトル抽出**
  - URLからの記事取得時に `og:title` / `h1` / `title` 等からタイトルを抽出し、本文先頭に `[title]` を付与（RSSは二重ヘッダを回避）。
- ✅ **Phase4の品質調整（具体性の底上げ）**
  - Reporterが本文から「引用候補」を抜粋してプロンプトに渡し、要約が一般論に寄りすぎないように制約を追加。
  - `summary` / `final_conclusion` が期待フォーマットを満たさない場合に、後処理で最低限の具体性・根拠・注意点を付与。
- ✅ **FactCheckerの安定化（JSON復元の標準化）**
  - `Critique` は structured output に依存せず、JSON文字列出力→パース復元で安定化。
  - JSON抽出を「フェンス除去＋最初にパースできたJSON採用＋型補完」に強化し、出力揺れに耐性を持たせた。
- ✅ **Reporterの安定化（2段＋段階フォールバック）**
  - 事実抽出（facts）→統合（report）の2段に分割。
  - どちらかが失敗しても最終レポートが空にならないよう、機械抽出/テンプレ合成で段階フォールバックを追加。
- ✅ **URL本文抽出の精度向上（readability）**
  - `readability-lxml` を導入し、可能ならreadabilityで本文抽出→失敗時は従来抽出へフォールバック。
- ✅ **`get_llm()` のモデル事前確認をオプション化**
  - `/api/tags` を毎回叩かないため、`get_llm(..., verify_model=...)` を追加。グラフ側は `verify_model=False` で軽量化。
- ✅ **セキュリティ（SSRF/外部HTTP）対策**
  - `src/utils/security.py` を追加し、外部HTTPアクセスを共通化（URL検証、拒否IPレンジ、DNS解決、リダイレクト制御、サイズ上限）。
  - URL直入力 / RSSフィード取得 / RSS由来記事URL取得のすべてに適用。
  - RSS許可リストは `RSS_FEEDS_FILE_ONLY=1`（推奨）でファイルのみ運用に寄せられる。
  - UIログはURLをマスクして記録（クエリ/フラグメント除去）。
  - 仕様は `docs/security_spec.md` に明文化。

## 6. 次の作業（優先度順）

1. **（レビュー反映）SSRF対策の強化（DNS Rebinding/TOCTOU）**
   - `validate_outbound_url()` のDNS解決チェックと実接続の間でDNSが変わる余地（TOCTOU）への追加対策を検討（IP固定接続＋Host固定等）。
   - **難易度が高めな理由**:
     - 事前にDNS解決してIPを検査しても、実際のHTTP接続はホスト名で行われるため、検証後にDNSが変わると“すり抜け”余地が残る（TOCTOU）。
     - HTTPSでは「IPへ直接接続」するとTLSのSNI/証明書検証（ホスト名一致）を両立させる必要があり、`requests` だけで安全に実装するのが難しい。
   - **現実的な対応策（優先順）**:
     - 運用で強化: `URL_ALLOWLIST_DOMAINS` を必須運用にし、信頼できる配信元ドメイン以外を遮断する。
     - 運用で強化: 既定どおり `URL_ALLOW_REDIRECTS=0` を維持（オープンリダイレクト経由の到達面を縮小）。
     - 実装で強化（中〜高コスト）: 事前に解決したIPへ接続しつつ Host/SNI を固定する方式（カスタムアダプタ/追加実装が必要になりやすい）。
2. **（レビュー反映）HTTPプロキシ環境変数の影響を制御**
   - `requests` が `HTTP_PROXY/HTTPS_PROXY` 等を拾う運用で想定外の経路になり得るため、`trust_env=False` 等の方針を検討。
3. **（レビュー反映）許可ポートのホワイトリスト化**
   - `validate_outbound_url()` にポート許可（例: 443のみ、必要なら80）を追加する方針を検討。
4. **（レビュー反映）UIの例外詳細表示の運用切替**
   - `st.exception(e)` の詳細表示を本番相当ではフラグで無効化（情報漏洩リスク低減）。
5. **（レビュー反映）危険入力・DoS耐性の追加**
   - `.local/.internal` 相当、異常に長いURL/ホスト名、`Content-Type` 欠落時の扱いなど、拒否条件/運用方針の明確化。
6. **（レビュー反映）ドキュメント更新（運用スイッチの明記）**
   - `RSS_ITEM_LINK_POLICY`（A/B切替）など、運用に影響する環境変数を `security_spec.md` に明記。
7. **（レビュー反映）保守性リファクタ（任意）**
   - `ResearcherAgent._fetch_from_url()` の責務分割（取得/タイトル/本文抽出/後処理）。
   - 楽観/悲観アナリストの重複整理（共通化/基底化）。
   - structured_output未対応モデル向けフォールバック方針の統一（アナリストもJSONフォールバック等）。


